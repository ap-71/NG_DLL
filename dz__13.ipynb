{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33ec9ad6",
   "metadata": {},
   "source": [
    "### Задание\n",
    "реализуйте задачу классификации на основе BERT-like модели и KNN на данных Russian Intents Dataset с Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597416d4",
   "metadata": {},
   "source": [
    "### Решение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814be5b1",
   "metadata": {},
   "source": [
    "#### Подключаем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fff80a5-1c65-4f22-93de-29e799fb732b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/asp/python/ng/NG_DLL/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from transformers import BertTokenizer, BertModel, AutoTokenizer, AutoModel, AutoModelForMaskedLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4b989d-21e4-43ee-95ad-a86c46a48deb",
   "metadata": {},
   "source": [
    "#### Загрузим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a62f69a-4fe3-41dd-bf08-a4adf14ba041",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = './dz__13'\n",
    "\n",
    "df_train = pd.read_csv(os.path.join(base_path, \"dataset_train.tsv\"), sep='\\t', header=None)\n",
    "df_test = pd.read_csv(os.path.join(base_path, \"dataset_test.tsv\"), sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ba42f8e-a4fc-48c4-9738-c27ec2333b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>как получить справку</td>\n",
       "      <td>statement_general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>мне нужна справка</td>\n",
       "      <td>statement_general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>справка студента эф петь</td>\n",
       "      <td>conform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>справка студента фф оформлять</td>\n",
       "      <td>conform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>как мне заказать справка об обучении</td>\n",
       "      <td>conform</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      0                  1\n",
       "0                  как получить справку  statement_general\n",
       "1                     мне нужна справка  statement_general\n",
       "2              справка студента эф петь            conform\n",
       "3         справка студента фф оформлять            conform\n",
       "4  как мне заказать справка об обучении            conform"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39d3e58d-7d59-4ace-b14b-d814868d7307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>мне нужна справка</td>\n",
       "      <td>statement_general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>оформить справку</td>\n",
       "      <td>statement_general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>взять справку</td>\n",
       "      <td>statement_general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>справку как получить</td>\n",
       "      <td>statement_general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>справку ммф где получаться</td>\n",
       "      <td>statement_general</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0                  1\n",
       "0           мне нужна справка  statement_general\n",
       "1            оформить справку  statement_general\n",
       "2               взять справку  statement_general\n",
       "3        справку как получить  statement_general\n",
       "4  справку ммф где получаться  statement_general"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "855cfe2b-32b6-40cd-ad2a-8f84cd36d529",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_data = torch.utils.data.DataLoader(df_train.to_records(index=False).tolist(), batch_size=10)\n",
    "Test_data = torch.utils.data.DataLoader(df_test.to_records(index=False).tolist(), batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4730d0-753a-4cf4-8af4-0b0b94e9b76c",
   "metadata": {},
   "source": [
    "#### Определим модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a47f1a0-b070-4e45-9604-659f9cc331a0",
   "metadata": {},
   "source": [
    "Стандартный BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5770c702-4339-4d22-b760-bdafbaf54ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|██████████| 29.0/29.0 [00:00<00:00, 23.1kB/s]\n",
      "vocab.txt: 100%|██████████| 996k/996k [00:00<00:00, 1.93MB/s]\n",
      "tokenizer.json: 100%|██████████| 1.96M/1.96M [00:00<00:00, 2.68MB/s]\n",
      "config.json: 100%|██████████| 625/625 [00:00<00:00, 1.20MB/s]\n",
      "model.safetensors: 100%|██████████| 714M/714M [01:37<00:00, 7.33MB/s] \n"
     ]
    }
   ],
   "source": [
    "tokenizer_1 = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model_1 = BertModel.from_pretrained(\"bert-base-multilingual-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec1befd-73c6-458e-a71e-22aae89ae34f",
   "metadata": {},
   "source": [
    "TwHIN-BERTt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cc19f16-c836-4f1b-8fad-d84f53d6d1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|██████████| 372/372 [00:00<00:00, 995kB/s]\n",
      "tokenizer.json: 100%|██████████| 17.1M/17.1M [00:02<00:00, 7.10MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 239/239 [00:00<00:00, 1.09MB/s]\n",
      "config.json: 100%|██████████| 632/632 [00:00<00:00, 1.18MB/s]\n",
      "model.safetensors: 100%|██████████| 1.12G/1.12G [02:08<00:00, 8.72MB/s]\n",
      "Some weights of BertModel were not initialized from the model checkpoint at Twitter/twhin-bert-base and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer_2 = AutoTokenizer.from_pretrained('Twitter/twhin-bert-base')\n",
    "model_2 = AutoModel.from_pretrained('Twitter/twhin-bert-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511577c0-0fb7-4072-92c5-7409675247e7",
   "metadata": {},
   "source": [
    "Sber BERT large model multitask (cased) for Sentence Embeddings in Russian language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5854ea71-2298-46d5-8820-ce91dcb2f87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|██████████| 331/331 [00:00<00:00, 507kB/s]\n",
      "config.json: 100%|██████████| 752/752 [00:00<00:00, 1.17MB/s]\n",
      "vocab.txt: 100%|██████████| 1.78M/1.78M [00:00<00:00, 4.91MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 170kB/s]\n",
      "pytorch_model.bin: 100%|██████████| 1.71G/1.71G [03:37<00:00, 7.87MB/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer_3 = AutoTokenizer.from_pretrained(\"ai-forever/sbert_large_mt_nlu_ru\")\n",
    "model_3 = AutoModel.from_pretrained(\"ai-forever/sbert_large_mt_nlu_ru\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6653178-468f-41ab-ab6c-70de8674e9fb",
   "metadata": {},
   "source": [
    "#### Получим признаки на основе Train и Tets датасетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1bb1a63-78eb-44f8-baff-c52fc0185268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask\n",
    "\n",
    "\n",
    "def get_embeddings(Data, tokenizer, model):\n",
    "    target_array = []\n",
    "    num = 1\n",
    "    for X, Y in Data:\n",
    "        encoded_input = tokenizer(X, return_tensors='pt', padding=True, truncation=True, max_length=30)\n",
    "        with torch.no_grad():\n",
    "            output = model(**encoded_input)\n",
    "\n",
    "        sentence_embeddings = mean_pooling(output, encoded_input['attention_mask'])\n",
    "\n",
    "        for i, sentence in enumerate(sentence_embeddings):\n",
    "            target_array.append((sentence, Y[i]))\n",
    "        print(f\"Done {num} out of {len(Data)}\", end='\\r')\n",
    "        num += 1\n",
    "    print('\\n')\n",
    "    \n",
    "    return target_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef005129-4898-4c34-bdd3-937c2bc99965",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 1323 out of 1323\n",
      "\n",
      "Done 89 out of 89\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Bert_base_train = get_embeddings(Train_data, tokenizer_1, model_1)\n",
    "Bert_base_test = get_embeddings(Test_data, tokenizer_1, model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29aace0e-eef3-49d4-9d37-b9bdff16af86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 1323 out of 1323\n",
      "\n",
      "Done 89 out of 89\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Bert_twit_train = get_embeddings(Train_data, tokenizer_2, model_2)\n",
    "Bert_twit_test = get_embeddings(Test_data, tokenizer_2, model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a659615-4664-4cc1-8891-18402273b0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 1323 out of 1323\n",
      "\n",
      "Done 89 out of 89\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Sber_train = get_embeddings(Train_data, tokenizer_3, model_3)\n",
    "Sber_test = get_embeddings(Test_data, tokenizer_3, model_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b0b274-72dd-46d0-a79b-824ec014068d",
   "metadata": {},
   "source": [
    "#### Сделаеми классфикацию KNN Test датасета, найдём точность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4acbc52e-7b14-4ef9-adaf-82f13196334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_accuracy(name, Data_train, Data_test, neigh):\n",
    "    X_train = [row[0].detach().numpy() for row in Data_train]\n",
    "    Y_train = [row[1] for row in Data_train]\n",
    "    neigh.fit(X_train, Y_train)\n",
    "    X_test = [row[0].detach().numpy() for row in Data_test]\n",
    "    Y_test = [row[1] for row in Data_test]\n",
    "    result = neigh.predict(X_test)\n",
    "    accuracy = result == Y_test\n",
    "    print(f\"Для модели {name} получена точность {sum(accuracy)/len(accuracy)*100} %\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972b3fdf-b58b-4a6b-b3f7-202517fc7c40",
   "metadata": {},
   "source": [
    "Стандартный BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfc5b546-6dde-4a0a-ac09-03f1b9fc7ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/Users/asp/python/ng/NG_DLL/.venv/lib/python3.10/site-packages/threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Для модели Base BERT получена точность 88.56172140430351 %\n"
     ]
    }
   ],
   "source": [
    "neigh_1 = KNeighborsClassifier(n_neighbors=10, weights='distance', n_jobs=-1)\n",
    "acc_1 = test_accuracy('Base BERT', Bert_base_train, Bert_base_test, neigh_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c47be7-aa38-469f-990f-0d7f75f8be8e",
   "metadata": {},
   "source": [
    "TwHIN-BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c8502d8-1d3d-4fcc-8e30-013c7ec67941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Для модели Twitter BERT получена точность 86.8629671574179 %\n"
     ]
    }
   ],
   "source": [
    "neigh_2 = KNeighborsClassifier(n_neighbors=10, weights='distance', n_jobs=-1)\n",
    "acc_2 = test_accuracy('Twitter BERT', Bert_twit_train, Bert_twit_test, neigh_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e682991-fd96-4232-8a54-cd6adc1e7029",
   "metadata": {},
   "source": [
    "Sber BERT large model multitask (cased) for Sentence Embeddings in Russian language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d17ff882-fce2-4c4b-a606-bf21300fa4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Для модели Sber BERT получена точность 87.76896942242357 %\n"
     ]
    }
   ],
   "source": [
    "neigh_3 = KNeighborsClassifier(n_neighbors=10, weights='distance', n_jobs=-1)\n",
    "acc_3 = test_accuracy('Sber BERT', Sber_train, Sber_test, neigh_3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
