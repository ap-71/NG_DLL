{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OHiAbU4HHkQn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision as tv\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8_zazpmEIMiW",
        "outputId": "34328930-2fae-4a6d-fdb8-97a023bd5527"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(**kwargs) -> None:\n",
        "    loss_ = kwargs['loss']\n",
        "    trainer_ = kwargs['trainer']\n",
        "    num_epochs_ = kwargs['num_epochs']\n",
        "    model_ = kwargs['model']\n",
        "    train_ = kwargs['train']\n",
        "    test_ = kwargs['test']\n",
        "    device_ = kwargs['device']\n",
        "    name = kwargs.get('name')\n",
        "    \n",
        "    model_ = model_.to(device_)\n",
        "\n",
        "    for epoch in range(num_epochs_):\n",
        "        train_iters, train_passed  = 0, 0\n",
        "        train_loss, train_acc = 0., 0.\n",
        "        n = 0\n",
        "        start=time.time()\n",
        "        \n",
        "        model_.train()\n",
        "        for i, (X, y)  in enumerate(train_):\n",
        "            X, y = X.to(device_), y.to(device_)\n",
        "            trainer_.zero_grad()\n",
        "            \n",
        "            if name == 'inception_v3':\n",
        "                y_pred, _ = model_(X)\n",
        "            else:\n",
        "                y_pred = model_(X)\n",
        "                \n",
        "            l = loss_(y_pred, y)\n",
        "            l.backward()\n",
        "            trainer_.step()\n",
        "            train_loss += l.item()\n",
        "            train_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
        "            train_iters += 1\n",
        "            train_passed += len(X)\n",
        "            n += y.shape[0]\n",
        "\n",
        "            if i % 50 == 0:\n",
        "              print(f\"Step {i}. time since epoch: {time.time() -  start:.3f}. \"\n",
        "                    f\"Train acc: {train_acc / n:.3f}. Train Loss: {train_loss / n:.3f}\")\n",
        "        \n",
        "        test_iters, test_passed  = 0, 0\n",
        "        test_loss, test_acc = 0., 0.\n",
        "        nt = 0\n",
        "        model_.eval()\n",
        "        for X, y in test_:\n",
        "            X, y = X.to(device_), y.to(device_)\n",
        "            \n",
        "            if name == 'inception_v3':\n",
        "                y_pred, _ = model_(X)\n",
        "            else:\n",
        "                y_pred = model_(X)\n",
        "                \n",
        "            l = loss_(y_pred, y)\n",
        "            test_loss += l.item()\n",
        "            test_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
        "            test_iters += 1\n",
        "            test_passed += len(X)\n",
        "            nt += y.shape[0]\n",
        "        \n",
        "        print(f'epoch {epoch + 1}, loss {train_loss / n:.4f}, train acc {train_acc / n:.3f}, test acc {test_acc / nt:.3f}, time {time.time() - start:.1f} sec')\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "BATCH_SIZE = 256\n",
        "\n",
        "transoforms = tv.transforms.Compose([\n",
        "    tv.transforms.Grayscale(3),\n",
        "    tv.transforms.Resize((224, 224)),\n",
        "    tv.transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_dataset = tv.datasets.EMNIST('./DSDZ4', train=True, transform=transoforms, download=True, split='mnist')\n",
        "test_dataset = tv.datasets.EMNIST('./DSDZ4', train=False, transform=transoforms, download=True, split='mnist')\n",
        "\n",
        "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
        "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset.targets.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tv.models.resnet18(pretrained=True)\n",
        "\n",
        "# Убираем требование градиента:\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "model.fc = nn.Linear(in_features=512, out_features=10)\n",
        "params_to_update = []\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "        params_to_update.append(param)\n",
        "        \n",
        "trainer = torch.optim.Adam(params_to_update, lr=0.001)\n",
        "\n",
        "train_loss_resnet18 = train_model(\n",
        "    loss=nn.CrossEntropyLoss(reduction='sum'),\n",
        "    trainer=trainer,\n",
        "    num_epochs=1,\n",
        "    model=model,\n",
        "    train=train_iter,\n",
        "    test=test_iter,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "# Step 0. time since epoch: 2.737. Train acc: 0.126. Train Loss: 2.348\n",
        "# Step 50. time since epoch: 130.843. Train acc: 0.735. Train Loss: 1.162\n",
        "# epoch 1, loss 1.0837, train acc 0.756, test acc 0.713, time 174.2 sec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tv.models.densenet161(pretrained=True)\n",
        "\n",
        "# Убираем требование градиента:\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "model.classifier = nn.Linear(in_features=2208, out_features=10)\n",
        "params_to_update = []\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "        params_to_update.append(param)\n",
        "        \n",
        "trainer = torch.optim.Adam(params_to_update, lr=0.001)\n",
        "\n",
        "train_loss_densenet161 = train_model(\n",
        "    loss=nn.CrossEntropyLoss(reduction='sum'),\n",
        "    trainer=trainer,\n",
        "    num_epochs=1,\n",
        "    model=model,\n",
        "    train=train_iter,\n",
        "    test=test_iter,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "# Step 0. time since epoch: 2.367. Train acc: 0.164. Train Loss: 2.318\n",
        "# Step 50. time since epoch: 117.742. Train acc: 0.726. Train Loss: 1.206\n",
        "# Step 100. time since epoch: 234.608. Train acc: 0.808. Train Loss: 0.867\n",
        "# Step 150. time since epoch: 350.229. Train acc: 0.847. Train Loss: 0.704\n",
        "# Step 200. time since epoch: 468.621. Train acc: 0.867. Train Loss: 0.606\n",
        "# epoch 1, loss 0.5601, train acc 0.877, test acc 0.943, time 629.4 sec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tv.models.vgg16(pretrained=True)\n",
        "\n",
        "# Убираем требование градиента:\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "model.classifier[6] = nn.Linear(in_features=4096, out_features=10)\n",
        "params_to_update = []\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "        params_to_update.append(param)\n",
        "        print(\"\\t\",name)\n",
        "        \n",
        "trainer = torch.optim.Adam(params_to_update, lr=0.001)\n",
        "\n",
        "train_loss_vgg16 = train_model(\n",
        "    loss=nn.CrossEntropyLoss(reduction='sum'),\n",
        "    trainer=trainer,\n",
        "    num_epochs=1,\n",
        "    model=model,\n",
        "    train=train_iter,\n",
        "    test=test_iter,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "# Step 0. time since epoch: 1.826. Train acc: 0.090. Train Loss: 2.396\n",
        "# Step 50. time since epoch: 82.464. Train acc: 0.692. Train Loss: 1.101\n",
        "# Step 100. time since epoch: 163.070. Train acc: 0.765. Train Loss: 0.838\n",
        "# Step 150. time since epoch: 243.769. Train acc: 0.796. Train Loss: 0.719\n",
        "# Step 200. time since epoch: 324.404. Train acc: 0.814. Train Loss: 0.648\n",
        "# epoch 1, loss 0.6129, train acc 0.824, test acc 0.933, time 440.1 sec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "BATCH_SIZE = 256\n",
        "transoforms = tv.transforms.Compose([\n",
        "    tv.transforms.Grayscale(3),\n",
        "    tv.transforms.Resize((299, 299)),\n",
        "    tv.transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_dataset = tv.datasets.EMNIST('./DSDZ4', train=True, transform=transoforms, download=True, split='mnist')\n",
        "test_dataset = tv.datasets.EMNIST('./DSDZ4', train=False, transform=transoforms, download=True, split='mnist')\n",
        "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
        "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "model = tv.models.inception_v3(pretrained=True)\n",
        "\n",
        "# Убираем требование градиента:\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "model.fc = nn.Linear(in_features=2048, out_features=10)\n",
        "params_to_update = []\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "        params_to_update.append(param)\n",
        "        print(\"\\t\",name)\n",
        "trainer = torch.optim.Adam(params_to_update, lr=0.001)\n",
        "\n",
        "train_loss_inception_v3 = train_model(\n",
        "    loss=nn.CrossEntropyLoss(reduction='sum'),\n",
        "    trainer=trainer,\n",
        "    num_epochs=1,\n",
        "    model=model,\n",
        "    train=train_iter,\n",
        "    test=test_iter,\n",
        "    device=device,\n",
        "    name='inception_v3'\n",
        ")\n",
        "\n",
        "# Step 0. time since epoch: 1.679. Train acc: 0.078. Train Loss: 2.349\n",
        "# Step 50. time since epoch: 88.405. Train acc: 0.584. Train Loss: 1.525\n",
        "# Step 100. time since epoch: 174.357. Train acc: 0.676. Train Loss: 1.209\n",
        "# Step 150. time since epoch: 260.755. Train acc: 0.721. Train Loss: 1.041\n",
        "# Step 200. time since epoch: 346.913. Train acc: 0.746. Train Loss: 0.939\n",
        "# epoch 1, loss 0.8865, train acc 0.764, test acc 0.000, time 422.5 sec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>resnet18</th>\n",
              "      <th>densenet161</th>\n",
              "      <th>vgg16</th>\n",
              "      <th>inception_v3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0837</td>\n",
              "      <td>0.5601</td>\n",
              "      <td>0.6129</td>\n",
              "      <td>0.8865</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   resnet18  densenet161   vgg16  inception_v3\n",
              "0    1.0837       0.5601  0.6129        0.8865"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame([[1.0837, 0.5601, 0.6129, 0.8865]], columns=['resnet18', 'densenet161', 'vgg16', 'inception_v3'])\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
